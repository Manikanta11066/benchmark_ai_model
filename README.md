# ğŸ§  AI Model Benchmarking Tool

A lightweight and efficient web-based tool to **benchmark AI models** across various performance metrics such as **accuracy**, **inference time**, and **memory usage**. Designed to support quick comparisons, insightful visualizations, and **PDF report generation**, this tool helps ML practitioners analyze and compare models in a streamlined workflow.

---

## ğŸš€ Features

- **ğŸ”¼ Upload & Benchmark**
  - Supports `.pt`, `.onnx`, and `.h5` model formats.
  - Extracts key performance metrics (accuracy, inference time, memory usage).
  
- **ğŸ“Š Comparison & Visualization**
  - Compare multiple AI models side-by-side.
  - Interactive and clear graphs for quick performance insights.
  
- **ğŸ“„ Report Generation**
  - Export benchmarking results as well-formatted **PDF reports**.
  - Includes summary tables and comparison charts.

---

## ğŸ› ï¸ Tech Stack

- **Backend:** Python, Flask
- **Model Handling:** PyTorch, TensorFlow, ONNX Runtime
- **Performance Tracking:** `psutil`, `time`, `memory_profiler`
- **Visualization:** Matplotlib, Seaborn
- **PDF Reports:** ReportLab / FPDF
- **Frontend:** *[Minimal - HTML Upload Form]*



